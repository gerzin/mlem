{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db1d6431-a487-4d13-ba93-a6d0e8a2a660",
   "metadata": {},
   "source": [
    "# Creation of BlackBox Models for the Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6059ddff-37fd-43c8-bf30-375a5bcf0f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014ece0b-9d64-43e5-a6cd-be38bcbae410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDED: /home/gerardozinno/Desktop/Tesi/Code/mlem\n"
     ]
    }
   ],
   "source": [
    "# ADD OTHER FOLDERS TO THIS LIST TO ADD THEM TO THE sys.path\n",
    "modules_to_add = [\"\"]\n",
    "\n",
    "this_file = os.path.abspath('')\n",
    "\n",
    "for module in modules_to_add:\n",
    "    p = Path(this_file).parent / module \n",
    "    if p.exists():\n",
    "        sys.path.append(str(p))\n",
    "        print(f\"ADDED: {p}\")\n",
    "    else:\n",
    "        print(f\"ERROR: {p} doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f6b52b-cd65-45d1-b8e1-05fa434798ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/gerardozinno/Desktop/Tesi/Code/mlem/notebooks', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python39.zip', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python3.9', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python3.9/lib-dynload', '', '/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages', '/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/IPython/extensions', '/home/gerardozinno/.ipython', '/home/gerardozinno/Desktop/Tesi/Code/mlem']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae5ae39-11be-4376-a398-11bf34d59a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "WHOLE_DATASET_PATH = Path(\"../data/adult/adult.csv\")\n",
    "TRAIN_PATH = WHOLE_DATASET_PATH.parent / \"train\" / \"train.csv\"\n",
    "TEST_PATH  = WHOLE_DATASET_PATH.parent / \"test\" / \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1524f88-090f-4383-a72d-faa1ec6957cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = .8\n",
    "RAND_SEED   = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f59ba6-0245-4097-89e0-fc5382f6b3dd",
   "metadata": {},
   "source": [
    "## Dataset creation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91d24e84-da12-493e-8bd0-5d1adc5eef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not WHOLE_DATASET_PATH.exists():\n",
    "    print(f\"downloading dataset from {DATASET_URL}\")\n",
    "    columns = ['Age', 'Workclass', 'Fnlwgt', 'Education', 'Education-num', 'Marital-status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital-gain', 'Capital-loss', 'Hours-per-week', 'Native-country', 'Target']\n",
    "    df = pd.read_csv(DATASET_URL, names=columns)\n",
    "    print(\"dataset downloaded\")\n",
    "    print(\"Cleaning and preprocessing dataset:\")\n",
    "    print(\"\\tdropping duplicates\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"\\ttrimming strings\")\n",
    "    df_str = df.select_dtypes(['object'])\n",
    "    df[df_str.columns] = df_str.apply(lambda x: x.str.strip())\n",
    "    print(\"\\tremoving rows with missing values (?)\")\n",
    "    for col in df_str.columns:\n",
    "        df = df[df[col] != '?']\n",
    "    print(\"Target Encoding the dataset\")\n",
    "    feat = df.iloc[:, :-1]\n",
    "    targ = df.iloc[:, -1]\n",
    "    map_targ = {\n",
    "        '<=50K': 0,\n",
    "        '>50K': 1\n",
    "    }\n",
    "    targ = targ.map(map_targ)\n",
    "\n",
    "    targenc = ce.TargetEncoder(verbose=1,return_df=True)\n",
    "    df = targenc.fit_transform(feat, targ)\n",
    "    df['Target'] = targ\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    WHOLE_DATASET_PATH.parent.mkdir(exist_ok=True)\n",
    "    df.to_csv(WHOLE_DATASET_PATH, index=False)\n",
    "\n",
    "    \n",
    "if not (TRAIN_PATH.exists() and TEST_PATH.exists()):\n",
    "    print(f\"Couldn't find the train and/or test dataset(s) in:\\n\\t{TRAIN_PATH}\\n\\t{TEST_PATH}\\n\")\n",
    "    if not WHOLE_DATASET_PATH.exists():\n",
    "        print(f\"ERROR: Couldn't even find {WHOLE_DATASET_PATH}\")\n",
    "        raise Exception(\"Can't find dataset\")\n",
    "    else:\n",
    "        \n",
    "        print(f\"Creating train and test sets with a split of {TRAIN_SPLIT}% - {1-TRAIN_SPLIT:.2f}% and {RAND_SEED} as random seed\")\n",
    "        print('The dataset is split \"as is\", without preprocessing. The selection of the right columns is made by the respective Dataloader')\n",
    "        df = pd.read_csv(WHOLE_DATASET_PATH, index_col=0)\n",
    "        train, test = train_test_split(df, train_size=TRAIN_SPLIT, shuffle=True, random_state=RAND_SEED)\n",
    "        TRAIN_PATH.parent.mkdir(exist_ok=True)\n",
    "        TEST_PATH.parent.mkdir(exist_ok=True)\n",
    "        train.to_csv(TRAIN_PATH, index=False)\n",
    "        test.to_csv(TEST_PATH, index=False)\n",
    "        print(\"train and test datasets created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4955a-5fd5-4b3c-90c6-1ae64bc7e656",
   "metadata": {},
   "source": [
    "# Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f0a2ad9-ec75-4051-942d-3d5891730203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(WHOLE_DATASET_PATH, index_col=0)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "assert(len(train) + len(test) == len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef4a6a0-9570-4282-ac92-52a2d4d5cb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22633\n",
       "1     7506\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c6a3c4-b000-4e2a-b988-1e51eb55594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4528\n",
       "1    1500\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15038d75-a5ec-4863-a48d-232d2e4ed756",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = train.to_numpy()\n",
    "test_np = test.to_numpy()\n",
    "\n",
    "X_train, y_train = train_np[:, :-1], train_np[:,-1]\n",
    "\n",
    "X_test, y_test = test_np[:, :-1], test_np[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e10fed-3f1f-45dc-aaf2-c55dcc58b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c025f055-9838-4013-8730-14fc86b31aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import sigmoid\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05c17527-c68e-4488-bdd3-a03ad32610a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import GenericDataset\n",
    "train_dataset = GenericDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "test_dataset = GenericDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "451f7d94-9896-42ce-bcf9-bb7c009cefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f538b-cadd-4e98-bd18-8e5670aac392",
   "metadata": {},
   "source": [
    "# Creating and fitting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c157b-85d8-4c1c-bc40-2e501ae6d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBinaryClassifier(nn.Module):\n",
    "    def __init__(self,input_shape):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5faaf-04f4-4525-9631-fdb3f4d62318",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleBinaryClassifier(input_shape=14)\n",
    "model.to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion   = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32f9cb-d8ec-4a07-aed2-801d511ee975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e822bef9-9068-48a7-934e-716ad5c05803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acd5b7-5226-4fa7-859e-5b37c4707275",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc96c13a-bae5-4e0d-9030-649e7b4b253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b337291a-686d-470d-81c8-b3dcdb79d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de4a14-1b5d-4a58-bb61-87becaa81d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"../pretrained/\")\n",
    "MODEL_NAME      = \"adult_1.tar\"\n",
    "SAVE_PATH = ROOT / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a824c6e-948d-44a0-aa44-aae2ab9f4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'X_train' : X_train,\n",
    "    'y_train' : y_train,\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test,\n",
    "    'activation': 'sigmoid',\n",
    "    'criterion': 'BCEWithLogitsLoss',\n",
    "    'input_shape': 14,\n",
    "    'epochs': EPOCHS,\n",
    "    'optimizer': 'ADAM'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e5bf0-6ce9-420d-9e85-fcf02dc061d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dic, SAVE_PATH)\n",
    "print(f\"SAVED: {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9bcb5-3145-42f3-852c-ab97cec18550",
   "metadata": {},
   "source": [
    "# Model with 2 values when predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "867ab802-6c09-4c77-a004-382b4c41512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBinaryClassifierP(nn.Module):\n",
    "    def __init__(self,input_shape):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        if not self.training:\n",
    "            x = torch.unsqueeze(x, -1)\n",
    "            x = torch.cat((x, -1*x), -1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f158325-420d-4250-86c2-27eb596500f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleBinaryClassifierP(\n",
      "  (fc1): Linear(in_features=14, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleBinaryClassifierP(input_shape=14)\n",
    "model.to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion   = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33473450-60e6-4cc4-bc76-1bbaf9e95cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02fc4e32-79cb-47c5-b23a-248782feabee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 35.12712 | Acc: 63.050\n",
      "Epoch 002: | Loss: 0.64625 | Acc: 76.249\n",
      "Epoch 003: | Loss: 0.57984 | Acc: 77.472\n",
      "Epoch 004: | Loss: 0.55661 | Acc: 78.279\n",
      "Epoch 005: | Loss: 0.52969 | Acc: 78.629\n",
      "Epoch 006: | Loss: 0.83899 | Acc: 78.297\n",
      "Epoch 007: | Loss: 0.51924 | Acc: 78.594\n",
      "Epoch 008: | Loss: 0.51669 | Acc: 78.411\n",
      "Epoch 009: | Loss: 0.52002 | Acc: 78.533\n",
      "Epoch 010: | Loss: 0.51896 | Acc: 78.313\n",
      "Epoch 011: | Loss: 0.51711 | Acc: 78.342\n",
      "Epoch 012: | Loss: 0.51860 | Acc: 78.358\n",
      "Epoch 013: | Loss: 0.52005 | Acc: 78.151\n",
      "Epoch 014: | Loss: 0.52472 | Acc: 78.183\n",
      "Epoch 015: | Loss: 0.51848 | Acc: 78.379\n",
      "Epoch 016: | Loss: 0.53303 | Acc: 77.411\n",
      "Epoch 017: | Loss: 0.53343 | Acc: 77.281\n",
      "Epoch 018: | Loss: 0.56505 | Acc: 75.401\n",
      "Epoch 019: | Loss: 0.56166 | Acc: 75.273\n",
      "Epoch 020: | Loss: 0.56084 | Acc: 75.114\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ffa730-5e97-42e8-8b90-670081b8eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74fb3820-e2fd-44c4-aab4-13d7c705a691",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33753/4017787481.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58f888-cae0-4e94-8c82-ce076fbdbb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfff62b-d2da-4dc1-a1be-244ec7b5708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"../pretrained/\")\n",
    "MODEL_NAME      = \"adult_1.tar\"\n",
    "SAVE_PATH = ROOT / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc98f8-f123-4312-9f99-a59f09d2b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'X_train' : X_train,\n",
    "    'y_train' : y_train,\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test,\n",
    "    'activation': 'sigmoid',\n",
    "    'criterion': 'BCEWithLogitsLoss',\n",
    "    'input_shape': 14,\n",
    "    'epochs': EPOCHS,\n",
    "    'optimizer': 'ADAM'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8503c34-2464-4925-81b3-a65a6c927d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dic, SAVE_PATH)\n",
    "print(f\"SAVED: {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be04bc-faab-43ce-b546-e4231b81e901",
   "metadata": {},
   "source": [
    "# Model With 2 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2110a1a-22ec-4604-8b60-8627e955750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBinaryClassifier2(nn.Module):\n",
    "    def __init__(self,input_shape):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc3 = nn.Linear(32,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79ad6afd-5361-4c9c-908d-7d3a106af3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleBinaryClassifier2(\n",
      "  (fc1): Linear(in_features=14, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleBinaryClassifier2(input_shape=14)\n",
    "model.to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion   = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2646bef-fbca-492f-99c2-d61dc0847d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc2(y_pred, y_test):\n",
    "    y_pred_tag = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ee9ddf2-5e44-4627-8bf1-83dd4d44c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, y = next(iter(train_loader))\n",
    "b = b.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68a40f7f-bd23-4735-ad1d-8351e354435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0e51e94-3411-4a4a-bad9-d7d859ef10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.argmax(torch.softmax(preds, dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c57c3ecc-fe06-47bf-9611-003c001c6fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.LongTensor'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05687cd7-60f9-42f9-9186-328587ca8e61",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15369/3433457974.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_acc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        y_pred_ = torch.softmax(y_pred, dim=1)\n",
    "        y_pred_ = torch.argmax(y_pred_, dim=1).float()\n",
    "        loss = criterion(y_pred_, y_batch)\n",
    "        acc = binary_acc2(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd4faf-4c32-4ad3-808b-ac4262b4e50c",
   "metadata": {},
   "source": [
    "# Saving the model and its data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0519f-a050-4fab-8bd9-7557451008e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d12c4594-2ea3-41bb-8fb1-4212e829d652",
   "metadata": {},
   "source": [
    "### TEST\n",
    "load the model just saved and compare its results against the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af340d-04cd-4869-a57d-ca48a74eb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TEST = True # Set to true to run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a924f4a-baf6-47c2-8061-7ad2bbdaad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TEST:\n",
    "    from mlem.black_box import PyTorchBlackBox\n",
    "\n",
    "    dic = torch.load(SAVE_PATH)\n",
    "\n",
    "    loaded_model = SimpleBinaryClassifier(14)\n",
    "    loaded_model.load_state_dict(dic['model_state_dict'])\n",
    "\n",
    "    model.cpu()\n",
    "    M = PyTorchBlackBox(model, activation=sigmoid)\n",
    "    LM = PyTorchBlackBox(loaded_model, activation=sigmoid)\n",
    "\n",
    "    loaded_preds = LM.predict(X_test[:10])\n",
    "    model_preds = M.predict(X_test[:10])\n",
    "\n",
    "    if not all(loaded_preds == model_preds):\n",
    "        print(\"The loaded model is not the same\")\n",
    "    else:\n",
    "        print(\"All's good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28502ec-0d81-4fb3-b9db-78f4afb36ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM.predict(X_test[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275ab43-3c85-4d7b-ab7a-62567af3b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM.predict_proba(X_test[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310dd94-ced4-4ce0-acbd-16b51c6c8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid_to_prob(x):\n",
    "    \n",
    "    \n",
    "LM2 = PyTorchBlackBox(model, activation=torch.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74205c-f21a-481f-803f-2ab5cc654987",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcb1df-d07d-49b3-a52d-acd5f76f320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X_test[:10], dtype=torch.float32, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7b456-fec5-48c9-944d-775a93a0b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8f516-b511-4d5f-a9e4-ced75b7736c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor.to(\"cpu\")\n",
    "y_out = loaded_model(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a4454-19f6-4362-af38-6042ab1e1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15cdf31-6ff5-4574-9009-cb51a7a446a0",
   "metadata": {},
   "source": [
    "# Using a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb392765-a8f9-48ae-a883-18c832987528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04da4cd3-e9a2-43a4-b072-ce8c2d8c27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf676f4-7d12-45cf-a736-f48d96804e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70ab0dc5-24b0-42f5-9522-92d42506b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ad729c9-9c17-4a5d-ad37-917d97f39335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4217,  311],\n",
       "       [ 556,  944]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43613b21-e006-4db3-992d-bd69f8475a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.91      4528\n",
      "         1.0       0.75      0.63      0.69      1500\n",
      "\n",
      "    accuracy                           0.86      6028\n",
      "   macro avg       0.82      0.78      0.80      6028\n",
      "weighted avg       0.85      0.86      0.85      6028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e58734-6b35-4a8a-a2ae-a9fefe5c2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlem.utilities import save_pickle_bz2, load_pickle_bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a11b0e8-4195-4666-924b-2d1dca3b48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"../pretrained/\")\n",
    "MODEL_NAME      = \"adult_rf.bz2\"\n",
    "SAVE_PATH = ROOT / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37730f0e-9587-4ecf-830f-d9b7467433e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle_bz2(SAVE_PATH, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6a1cc83-d062-46fa-85fd-2e1d1fe2903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "                SAVE_PATH.parent / \"adultdata\",\n",
    "                x_train=X_train,\n",
    "                x_test=X_test,\n",
    "                y_train=y_train,\n",
    "                y_test=y_test,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf83182-382e-4961-94ec-62a29fd68a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c50d6371-621f-4a25-9f72-0e23f3993a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(SAVE_PATH.parent / \"adultdata.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31f175b6-1092-4108-b136-1f6fad59537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.20000000e+01, 2.18918433e-01, 2.29732000e+05, ...,\n",
       "        0.00000000e+00, 4.50000000e+01, 2.54411176e-01],\n",
       "       [4.20000000e+01, 2.18918433e-01, 1.36986000e+05, ...,\n",
       "        0.00000000e+00, 4.00000000e+01, 2.54411176e-01],\n",
       "       [2.40000000e+01, 2.18918433e-01, 2.04935000e+05, ...,\n",
       "        0.00000000e+00, 5.60000000e+01, 2.54411176e-01],\n",
       "       ...,\n",
       "       [2.80000000e+01, 2.18918433e-01, 4.41620000e+05, ...,\n",
       "        0.00000000e+00, 4.30000000e+01, 5.44554455e-02],\n",
       "       [5.10000000e+01, 2.18918433e-01, 1.71914000e+05, ...,\n",
       "        0.00000000e+00, 5.00000000e+01, 2.54411176e-01],\n",
       "       [3.10000000e+01, 2.18918433e-01, 3.25500000e+04, ...,\n",
       "        0.00000000e+00, 4.00000000e+01, 2.54411176e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded['x_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd43de1-0527-470e-9499-f0e1e77e619c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bd49468-4da7-4e7b-9755-d0e92731259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1e0793c-4724-430e-a491-2723d0a96b63",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../pretrained/adult_rf.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20206/2512557868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_PATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"adult_rf.tar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[1;32m    195\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../pretrained/adult_rf.tar'"
     ]
    }
   ],
   "source": [
    "(SAVE_PATH.parent / \"adult_rf.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3de6c9e0-60b0-4d4a-9a73-aea0fb07f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f902dfa7-7cb5-4f91-b272-f5a4d536418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_loaded = load_pickle_bz2(SAVE_PATH.parent / \"adult_rf.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a69fdc29-049d-4bbb-959b-f8488a78750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf_loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5da8d36e-8d65-44d6-aa79-c93b63e0cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = [i for i,j in enumerate(preds) if j == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af268345-6015-4e96-b67b-03d4e9438054",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf1b751c-dabf-4800-b48c-d4b286a1c6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0151ca7-67d3-484d-9928-8926b767fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "preds_loaded = rf_loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00bccfcc-0042-4320-8af9-4b709739c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all(preds == preds_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5108c41e-453b-4f68-8f87-225edf9cc353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71, 0.29],\n",
       "       [0.76, 0.24],\n",
       "       [0.93, 0.07],\n",
       "       ...,\n",
       "       [0.57, 0.43],\n",
       "       [0.2 , 0.8 ],\n",
       "       [1.  , 0.  ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e41564c-8924-4859-b541-362e0935f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlem.black_box import SklearnBlackBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db2c4b9a-5cd9-4031-9aa3-593aa65f4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = SklearnBlackBox(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f573758b-f74f-4bfb-8231-56e4b68b8b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6c5c23f-ed12-4814-811f-3194f987d32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71, 0.29],\n",
       "       [0.76, 0.24],\n",
       "       [0.93, 0.07],\n",
       "       ...,\n",
       "       [0.57, 0.43],\n",
       "       [0.2 , 0.8 ],\n",
       "       [1.  , 0.  ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0c6ee62-43fb-4c18-a8b2-bb2704b52d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100e7f0-4b6b-447b-9079-c583299b971d",
   "metadata": {},
   "source": [
    "# Extract Balanced Subset from Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d393f606-5b57-49e9-b40f-a96adb459de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1691e98d-3138-4b86-8fd8-d4700e05b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "979be4dc-9576-4987-9bc8-a41f48c82428",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = [i for (i,j) in enumerate(y_train) if j == 1]\n",
    "zeros = [i for (i,j) in enumerate(y_train) if j == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "127f44aa-1b67-4233-a4b6-18ad804f4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ones = X_train[ones]\n",
    "X_zeros = X_train[zeros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7f17735-7ec7-4d85-b414-aa19a317ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_ones)+len(X_zeros) == len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5870b4cd-ab95-4142-b526-51973a2f10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_zeros = X_zeros[:len(X_ones)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "22c2c94f-0f7e-49a1-9564-f9fd1d764e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_balanced = np.concatenate([X_ones, X_zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "825d5af2-b7f5-4319-a931-b6dcc05beaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_balanced = np.concatenate([np.ones(len(X_ones)), np.zeros(len(X_zeros))]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "af484d9a-7b10-4083-b75b-7dcea1f60ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unisonShuffleDataset(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d99bd77f-9205-406f-aa28-d1e18a748321",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_balanced, y_train_balanced = unisonShuffleDataset(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ac2c0d86-2205-4371-b0fa-18a50d5a2663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert sum(y_train_balanced) == len(y_train_balanced) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2bc6dd92-0ef6-4cbf-9aab-1bcff1ac9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bal = RandomForestClassifier(n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7bf51b19-8e61-4af9-a6f8-c68b1305a81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "406d9404-b1ca-434c-b436-b45037216df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e656c1ae-e5b1-42cc-b16e-cfbb149e00a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3685,  843],\n",
       "       [ 254, 1246]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c61015c-e769-4f48-8a66-0f2f4b208b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87      4528\n",
      "           1       0.60      0.83      0.69      1500\n",
      "\n",
      "    accuracy                           0.82      6028\n",
      "   macro avg       0.77      0.82      0.78      6028\n",
      "weighted avg       0.85      0.82      0.83      6028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e33623ab-3fb5-4b7a-81ef-1d0e5ae9e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5436925-04ae-4ff4-97cd-8bcbc7a464fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b188898-607f-49d1-92cb-53f511b229c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([o,z]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167cea7-9760-4152-86f2-90bf0613181e",
   "metadata": {},
   "source": [
    "# LOAD THE MODEL TRAINED ON THE SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77fc399-d9cb-454f-9d0a-c0fe57b4f4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rand_for = load_pickle_bz2(\"../pretrained/adult_randfor.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dae98e84-e0ec-40ff-b498-9f67ab5cca63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sqrt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for.max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1394953-0c24-4312-9eb5-9613e262c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../pretrained/adult_randfor.data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8021b338-1878-4ccf-9136-a09d619adfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train\n",
      "x_test\n",
      "y_train\n",
      "y_test\n"
     ]
    }
   ],
   "source": [
    "for k in data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86c7fd06-8e45-4870-846e-35f816e89864",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = data['x_test'], data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b44e7f3c-054d-40a4-a808-d5560cda4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rand_for.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a3421f8-0444-4367-8686-fb997731a008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8651293961512939"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586517b-dd96-4171-b35b-0e452c0238b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
