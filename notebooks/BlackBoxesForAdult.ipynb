{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db1d6431-a487-4d13-ba93-a6d0e8a2a660",
   "metadata": {},
   "source": [
    "# Creation of BlackBox Models for the Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6059ddff-37fd-43c8-bf30-375a5bcf0f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014ece0b-9d64-43e5-a6cd-be38bcbae410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDED: /home/gerardozinno/Desktop/Tesi/Code/mlem\n"
     ]
    }
   ],
   "source": [
    "# ADD OTHER FOLDERS TO THIS LIST TO ADD THEM TO THE sys.path\n",
    "modules_to_add = [\"\"]\n",
    "\n",
    "this_file = os.path.abspath('')\n",
    "\n",
    "for module in modules_to_add:\n",
    "    p = Path(this_file).parent / module \n",
    "    if p.exists():\n",
    "        sys.path.append(str(p))\n",
    "        print(f\"ADDED: {p}\")\n",
    "    else:\n",
    "        print(f\"ERROR: {p} doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f6b52b-cd65-45d1-b8e1-05fa434798ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/gerardozinno/Desktop/Tesi/Code/mlem/notebooks', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python39.zip', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python3.9', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python3.9/lib-dynload', '', '/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages', '/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/IPython/extensions', '/home/gerardozinno/.ipython', '/home/gerardozinno/Desktop/Tesi/Code/mlem']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae5ae39-11be-4376-a398-11bf34d59a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "WHOLE_DATASET_PATH = Path(\"../data/adult/adult.csv\")\n",
    "TRAIN_PATH = WHOLE_DATASET_PATH.parent / \"train\" / \"train.csv\"\n",
    "TEST_PATH  = WHOLE_DATASET_PATH.parent / \"test\" / \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1524f88-090f-4383-a72d-faa1ec6957cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = .8\n",
    "RAND_SEED   = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f59ba6-0245-4097-89e0-fc5382f6b3dd",
   "metadata": {},
   "source": [
    "## Dataset creation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91d24e84-da12-493e-8bd0-5d1adc5eef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not WHOLE_DATASET_PATH.exists():\n",
    "    print(f\"downloading dataset from {DATASET_URL}\")\n",
    "    columns = ['Age', 'Workclass', 'Fnlwgt', 'Education', 'Education-num', 'Marital-status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital-gain', 'Capital-loss', 'Hours-per-week', 'Native-country', 'Target']\n",
    "    df = pd.read_csv(DATASET_URL, names=columns)\n",
    "    print(\"dataset downloaded\")\n",
    "    print(\"Cleaning and preprocessing dataset:\")\n",
    "    print(\"\\tdropping duplicates\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"\\ttrimming strings\")\n",
    "    df_str = df.select_dtypes(['object'])\n",
    "    df[df_str.columns] = df_str.apply(lambda x: x.str.strip())\n",
    "    \n",
    "    WHOLE_DATASET_PATH.parent.mkdir(exist_ok=True)\n",
    "    df.to_csv(WHOLE_DATASET_PATH)\n",
    "\n",
    "    \n",
    "if not (TRAIN_PATH.exists() and TEST_PATH.exists()):\n",
    "    print(f\"Couldn't find the train and/or test dataset(s) in:\\n\\t{TRAIN_PATH}\\n\\t{TEST_PATH}\\n\")\n",
    "    if not WHOLE_DATASET_PATH.exists():\n",
    "        print(f\"ERROR: Couldn't even find {WHOLE_DATASET_PATH}\")\n",
    "        raise Exception(\"Can't find dataset\")\n",
    "    else:\n",
    "        \n",
    "        print(f\"Creating train and test sets with a split of {TRAIN_SPLIT}% - {1-TRAIN_SPLIT:.2f}% and {RAND_SEED} as random seed\")\n",
    "        print('The dataset is split \"as is\", without preprocessing. The selection of the right columns is made by the respective Dataloader')\n",
    "        df = pd.read_csv(WHOLE_DATASET_PATH)\n",
    "        train, test = train_test_split(df, train_size=TRAIN_SPLIT, shuffle=True, random_state=RAND_SEED)\n",
    "        TRAIN_PATH.parent.mkdir(exist_ok=True)\n",
    "        TEST_PATH.parent.mkdir(exist_ok=True)\n",
    "        train.to_csv(TRAIN_PATH, index=False)\n",
    "        test.to_csv(TEST_PATH, index=False)\n",
    "        print(\"train and test datasets created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81892dba-100a-4da5-98d0-27d3049bf2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
