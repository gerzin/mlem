{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9a3518-cf89-4948-93c0-2a9a7a1c1b32",
   "metadata": {},
   "source": [
    "# In this notebook I add noise to all the Diva validation datasets created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f131ebf-f524-45ce-975c-229990e65561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import bz2\n",
    "import pickle\n",
    "np.random.seed(10)\n",
    "# adds the visibility of the mlem module, needed to load the attack models\n",
    "sys.path.append(\"../../../\") \n",
    "import mlem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f2411-b501-4c1a-a6f4-0d5f45ead4bb",
   "metadata": {},
   "source": [
    "Functions used to generate the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a2c40b-8262-41cd-ab6e-492bacb8511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_noise_numerical_diva(dataset: pd.DataFrame, perc: float = 0.1):\n",
    "    \"\"\"\n",
    "    Insert noise in the Diva dataset. Assumes all columns are numerical and the noise is sampled from a normal distr, with same mean and std of the column.\n",
    "    \n",
    "    Args:\n",
    "        dataset (DataFrame): dataset on which to insert the noise.\n",
    "        perc (float): percentage of noise in the range [0,1]\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> df = pd.DataFrame(data={'col1': 10 * [1], 'col2': 10 * [2], 'col3': 10 * [3]})\n",
    "        >>> df[NUMERICAL] = insert_noise_numerical(df[NUMERICAL].copy(), perc=0.1, noise_generating_function=np.random.rand) # note np.random.rand has a size parameter\n",
    "\n",
    "    \"\"\"\n",
    "    n_rows, n_col = dataset.shape\n",
    "    percentage = int(perc * n_rows)\n",
    "\n",
    "    for c in range(n_col):\n",
    "        index_to_replace = np.random.choice(dataset.index,\n",
    "                                            size=percentage)\n",
    "        mean = dataset[dataset.columns[c]].mean()\n",
    "        std  = dataset[dataset.columns[c]].std()\n",
    "          \n",
    "        new_values = np.random.normal(loc=mean, scale=std, size=percentage)\n",
    "        assert (len(index_to_replace) == len(new_values))\n",
    "        for ind, val in zip(index_to_replace, new_values):\n",
    "            dataset.iloc[ind, c] = val\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f9d460-367c-4a40-8481-aa69a78dc55b",
   "metadata": {},
   "source": [
    "Paths of all the validation datasets on which to insert the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f5e381-20bd-4969-b92d-f7f07670a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = [\n",
    "    Path(\"diva_outputs/diva_validation.csv\")\n",
    "]\n",
    "\n",
    "assert all(map(lambda x: x.is_file(), PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b144a2-ce79-4220-9b9a-926738f2dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diva_outputs/diva_validation.csv\n"
     ]
    }
   ],
   "source": [
    "for p in PATHS:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819a81c-09ad-4def-9151-2a8a7ea86192",
   "metadata": {},
   "source": [
    "Adding the noise and saving the datasets in the same folder of the clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d8a6ac-d355-4464-9e3a-d895f3a2d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in PATHS:\n",
    "    clean = pd.read_csv(p)\n",
    "    feature_columns = clean.columns[1:-2]\n",
    "    \n",
    "    noised = insert_noise_numerical_diva(clean.copy()[feature_columns])\n",
    "    \n",
    "    clean[feature_columns] = noised\n",
    "    \n",
    "    \n",
    "    new_name = p.name.replace(\".csv\", \"-noisy.csv\")\n",
    "    new_path = p.parent / new_name\n",
    "    clean.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add33d21-b8f6-4804-a02a-e92c46a5da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(\"diva_outputs/diva_minmax_randfor_data.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
