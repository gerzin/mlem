{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9a3518-cf89-4948-93c0-2a9a7a1c1b32",
   "metadata": {},
   "source": [
    "# In this notebook I add noise to all the adult validation datasets created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f131ebf-f524-45ce-975c-229990e65561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import bz2\n",
    "import pickle\n",
    "np.random.seed(10)\n",
    "# adds the visibility of the mlem module, needed to load the attack models\n",
    "sys.path.append(\"../../../\") \n",
    "import mlem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f2411-b501-4c1a-a6f4-0d5f45ead4bb",
   "metadata": {},
   "source": [
    "Functions used to generate the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f37a88-6cd2-4f83-a8ab-d5d85aa1ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from numpy import array\n",
    "def frequency_based_noise(column, size):\n",
    "    \"\"\"\n",
    "    Sample values from a column with replacement.\n",
    "\n",
    "    Args:\n",
    "        column: column to sample from\n",
    "        size: number of elements to sample\n",
    "\n",
    "    Returns:\n",
    "        Array of samples\n",
    "    \"\"\"\n",
    "    return column.sample(size, replace=True).to_numpy()\n",
    "\n",
    "def insert_noise_categorical(dataset: pd.DataFrame, perc: float = 0.1,\n",
    "                             noise_generating_function: Callable[[pd.Series, int], array] = frequency_based_noise):\n",
    "    \"\"\"\n",
    "    Insert noise in a categorical dataset and returns the dataset passed as argument.\n",
    "        \n",
    "    Args:\n",
    "        dataset (DataFrame): dataset on which to insert the noise ( it should only contain categorical variables )\n",
    "        perc (float): percentage of noise in the range [0,1]\n",
    "       noise_generating_function (Callable[[int], array]): function used to generate the noise, must take as input the number of noisy values to\n",
    "                                   generate inside an argument named size and return an array containing the random values.\n",
    "\n",
    "    Returns:\n",
    "        dataset\n",
    "    \"\"\"\n",
    "    n_rows, n_col = dataset.shape\n",
    "    percentage = int(perc * n_rows)\n",
    "\n",
    "    for c in range(n_col):\n",
    "        index_to_replace = np.random.choice(dataset.index,\n",
    "                                            size=percentage)\n",
    "        new_values = noise_generating_function(dataset[dataset.columns[c]], size=percentage)\n",
    "        assert (len(index_to_replace) == len(new_values))\n",
    "        for ind, val in zip(index_to_replace, new_values):\n",
    "            dataset.iloc[ind, c] = val\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a2c40b-8262-41cd-ab6e-492bacb8511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_noise_numerical(dataset: pd.DataFrame, perc: float = 0.1,\n",
    "                           noise_generating_function: Callable[[int], array] = np.random.normal):\n",
    "    \"\"\"\n",
    "    Insert noise in a numerical dataset and returns the dataset passed as argument.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): dataset on which to insert the noise.\n",
    "        perc (float): percentage of noise in the range [0,1]\n",
    "        noise_generating_function (Callable[[int], array]): function used to generate the noise, must take as input the number of noisy values to\n",
    "                                   generate inside an argument named size and return an array containing the random values.\n",
    "\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> df = pd.DataFrame(data={'col1': 10 * [1], 'col2': 10 * [2], 'col3': 10 * [3]})\n",
    "        >>> df[NUMERICAL] = insert_noise_numerical(df[NUMERICAL].copy(), perc=0.1, noise_generating_function=np.random.rand) # note np.random.rand has a size parameter\n",
    "\n",
    "    \"\"\"\n",
    "    n_rows, n_col = dataset.shape\n",
    "    percentage = int(perc * n_rows)\n",
    "\n",
    "    for c in range(n_col):\n",
    "        index_to_replace = np.random.choice(dataset.index,\n",
    "                                            size=percentage)\n",
    "        new_values = noise_generating_function(size=percentage)\n",
    "        assert (len(index_to_replace) == len(new_values))\n",
    "        for ind, val in zip(index_to_replace, new_values):\n",
    "            dataset.iloc[ind, c] = val\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f9d460-367c-4a40-8481-aa69a78dc55b",
   "metadata": {},
   "source": [
    "Paths of all the validation datasets on which to insert the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f8b59e-3669-44e5-85c0-bbbfde9877db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult_no_target_division/K2/validation_k2.csv\n",
      "adult_no_target_division/K3/validation_k3.csv\n",
      "adult_no_target_division/K4/validation_k4.csv\n",
      "adult_no_target_division/K5/validation_k5.csv\n",
      "adult_no_target_division/K6/validation_k6.csv\n",
      "adult_randomforest_and_datasets/adult_validationset.csv\n"
     ]
    }
   ],
   "source": [
    "PATHS = []\n",
    "for k in range(2,7):\n",
    "    PATHS.append(Path(f\"adult_no_target_division/K{k}/validation_k{k}.csv\"))\n",
    "PATHS.append(Path(\"adult_randomforest_and_datasets/adult_validationset.csv\"))\n",
    "assert all(map(lambda x: x.is_file(), PATHS))\n",
    "\n",
    "for p in PATHS:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa29bdb9-8f2f-4389-845e-6c5c03d0fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = ['Age', 'Fnlwgt', 'Education-num', 'Capital-gain', 'Capital-loss', 'Hours-per-week']\n",
    "CATEGORICAL_FEATURES = ['Relationship','Native-country','Workclass','Sex','Marital-status','Education','Occupation','Race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2cf33f8-2f78-4b20-8ba7-f34c7910c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_NOISE_PERC = 0.1\n",
    "CATEGORICAL_NOISE_PERC = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819a81c-09ad-4def-9151-2a8a7ea86192",
   "metadata": {},
   "source": [
    "Adding the noise and saving the datasets in the same folder of the clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04d8a6ac-d355-4464-9e3a-d895f3a2d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in PATHS:\n",
    "    clean = pd.read_csv(p)\n",
    "    clean[NUMERICAL_FEATURES] = insert_noise_numerical(clean[NUMERICAL_FEATURES].copy(), perc=NUMERICAL_NOISE_PERC)\n",
    "    clean[CATEGORICAL_FEATURES] = insert_noise_categorical(clean[CATEGORICAL_FEATURES].copy(), perc=CATEGORICAL_NOISE_PERC)\n",
    "    new_name = p.name.replace(\".csv\", \"-noisy.csv\")\n",
    "    new_path = p.parent / new_name\n",
    "    clean.to_csv(new_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
