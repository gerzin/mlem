{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a6e0a9-569b-4845-8bc1-823316f42600",
   "metadata": {},
   "source": [
    "# Creation of BlackBox Models for the Geotarget30 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b8809f-83c8-40c4-a3e3-aaa150b0bd90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdb07d1-3481-4a5e-ae42-4ca7c2a2ffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDED: /home/gerardozinno/Desktop/Tesi/Code/mlem\n"
     ]
    }
   ],
   "source": [
    "# ADD OTHER FOLDERS TO THIS LIST TO ADD THEM TO THE sys.path\n",
    "modules_to_add = [\"\"]\n",
    "\n",
    "this_file = os.path.abspath('')\n",
    "\n",
    "for module in modules_to_add:\n",
    "    p = Path(this_file).parent / module \n",
    "    if p.exists():\n",
    "        sys.path.append(str(p))\n",
    "        print(f\"ADDED: {p}\")\n",
    "    else:\n",
    "        print(f\"ERROR: {p} doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d104fe6d-29ee-492f-8f60-4e995cade77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/gerardozinno/Desktop/Tesi/Code/mlem/notebooks', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python39.zip', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python3.9', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python3.9/lib-dynload', '', '/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages', '/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/IPython/extensions', '/home/gerardozinno/.ipython', '/home/gerardozinno/Desktop/Tesi/Code/mlem']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1ee39-e6ea-495f-9151-13c895a6b5fe",
   "metadata": {},
   "source": [
    "# CREATING THE TRAIN AND TEST DATASETS (if they aren't in the respective folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322a4c78-742f-4ecb-b254-43f3e2d85457",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHOLE_DATASET_PATH = Path(\"../data/geotarget/geotarget_30.csv\")\n",
    "TRAIN_PATH = WHOLE_DATASET_PATH.parent / \"train\" / \"train.csv\"\n",
    "TEST_PATH  = WHOLE_DATASET_PATH.parent / \"test\" / \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4eb169f-e23c-40a5-b9e2-6e6067f7239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = .8\n",
    "RAND_SEED   = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d6fd06-d9e2-4c6e-9531-58c84c0d32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (TRAIN_PATH.exists() and TEST_PATH.exists()):\n",
    "    print(f\"Couldn't find the train and/or test dataset(s) in:\\n\\t{TRAIN_PATH}\\n\\t{TEST_PATH}\\n\")\n",
    "    if not WHOLE_DATASET_PATH.exists():\n",
    "        print(f\"ERROR: Couldn't even find {WHOLE_DATASET_PATH}\")\n",
    "        raise Exception(\"Can't find dataset\")\n",
    "    else:\n",
    "        \n",
    "        print(f\"Creating train and test sets with a split of {TRAIN_SPLIT}% - {1-TRAIN_SPLIT:.2f}% and {RAND_SEED} as random seed\")\n",
    "        print('The dataset is split \"as is\", without preprocessing. The selection of the right columns is made by the respective Dataloader')\n",
    "        df = pd.read_csv(WHOLE_DATASET_PATH)\n",
    "        train, test = train_test_split(df, train_size=TRAIN_SPLIT, shuffle=True, random_state=RAND_SEED)\n",
    "        TRAIN_PATH.parent.mkdir(exist_ok=True)\n",
    "        TEST_PATH.parent.mkdir(exist_ok=True)\n",
    "        train.to_csv(TRAIN_PATH, index=False)\n",
    "        test.to_csv(TEST_PATH, index=False)\n",
    "        print(\"train and test datasets created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc3f16-2cf7-4559-86bd-4fbb6cf09b3f",
   "metadata": {},
   "source": [
    "# CREATING THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e7b909-964a-466d-a490-fdee494a1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from blackboxes.pytorch.linear import LinearDropLinear\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4019bbc-032f-477f-9a10-36272a7f15a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving model to GPU\n",
      "LinearDropLinear(\n",
      "  (fc1): Linear(in_features=236, out_features=128, bias=True)\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      "  (fc4): Linear(in_features=128, out_features=30, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LinearDropLinear()\n",
    "if device.type == \"cuda\":\n",
    "    print(\"moving model to GPU\")\n",
    "    model = model.cuda()\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f17bfe-547e-440c-b440-e6d3655c156f",
   "metadata": {},
   "source": [
    "# LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105838b0-dd14-4bf8-9b29-b60feb0f1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.geotarget import Geotarget30\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe65b40-32b3-4224-8908-35d18777ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Geotarget30(TRAIN_PATH)\n",
    "test_set  = Geotarget30(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b24ce34-9486-4a1d-8b23-616f7d8c3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=64)\n",
    "test_dataloader  = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86268a1e-f1bb-4437-a3b4-9acf0715cd5a",
   "metadata": {},
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53b0c87-6075-4116-8dfb-6f2fe5e8269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfbb1f8d-1441-4375-912c-6660628ece99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blackboxes.pytorch.utilities import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfc4e6d1-9826-46d8-a65a-33c05445e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd5e7a17-1294-43bd-b016-98ce3b16b0ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (30) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24041/1517766009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Tesi/Code/mlem/blackboxes/pytorch/utilities.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, train_loader, test_loader, epochs, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mnum_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (30) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, loss_fn, train_dataloader, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a32dc0-7ec7-42bc-9867-a0acb079f742",
   "metadata": {},
   "source": [
    "### Save the model and other infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "578fd931-552d-44cb-809b-05bf1c017537",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"../pretrained/\")\n",
    "MODEL_NAME      = \"linear_geo30.tar\"\n",
    "SAVE_PATH = ROOT / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b63f83-ba56-4766-9f7a-687a9aa5f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_set[:]\n",
    "x_test, y_test = test_set[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1fb828-b395-425f-8d0a-9d0c68b13c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'x_train' : x_train,\n",
    "    'y_train' : y_train,\n",
    "    'x_test': x_test,\n",
    "    'y_test': y_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "062044d1-7373-48e1-a3c5-910639b79255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ../pretrained/linear_geo30.tar\n"
     ]
    }
   ],
   "source": [
    "torch.save(dic, SAVE_PATH)\n",
    "print(f\"SAVED: {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784c79c-9249-43cc-b59b-5f158d0a98ef",
   "metadata": {},
   "source": [
    "### TEST\n",
    "load the model just saved and compare its results against the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d075548c-f15e-4f37-bc4f-294c43c18e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TEST = False # Set to true to run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67488b77-eaae-4168-a336-184054dfcd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All's good\n"
     ]
    }
   ],
   "source": [
    "if RUN_TEST:\n",
    "    from mlem.black_box import PyTorchBlackBox\n",
    "\n",
    "    dic = torch.load(SAVE_PATH)\n",
    "\n",
    "    loaded_model = LinearDropLinear()\n",
    "    loaded_model.load_state_dict(dic['model_state_dict'])\n",
    "\n",
    "    model.cpu()\n",
    "    M = PyTorchBlackBox(model)\n",
    "    LM = PyTorchBlackBox(loaded_model)\n",
    "\n",
    "    loaded_preds = LM.predict(x_test[:10])\n",
    "    model_preds = M.predict(x_test[:10])\n",
    "\n",
    "    if not all(loaded_preds == model_preds):\n",
    "        print(\"The loaded model is not the same\")\n",
    "    else:\n",
    "        print(\"All's good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8396b5-422e-4e5f-b216-ce98f8ab097a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
