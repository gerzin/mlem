{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a6e0a9-569b-4845-8bc1-823316f42600",
   "metadata": {},
   "source": [
    "# Creation of BlackBox Models for the Geotarget30 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b8809f-83c8-40c4-a3e3-aaa150b0bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdb07d1-3481-4a5e-ae42-4ca7c2a2ffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDED: /home/gerardozinno/Desktop/Tesi/Code/mlem\n"
     ]
    }
   ],
   "source": [
    "# ADD OTHER FOLDERS TO THIS LIST TO ADD THEM TO THE sys.path\n",
    "modules_to_add = [\"\"]\n",
    "\n",
    "this_file = os.path.abspath('')\n",
    "\n",
    "for module in modules_to_add:\n",
    "    p = Path(this_file).parent / module \n",
    "    if p.exists():\n",
    "        sys.path.append(str(p))\n",
    "        print(f\"ADDED: {p}\")\n",
    "    else:\n",
    "        print(f\"ERROR: {p} doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d104fe6d-29ee-492f-8f60-4e995cade77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/gerardozinno/Desktop/Tesi/Code/mlem/notebooks', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python39.zip', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python3.9', '/home/gerardozinno/.pyenv/versions/3.9.9/lib/python3.9/lib-dynload', '', '/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages', '/home/gerardozinno/.pyenv/versions/3.9.9/envs/ml-environment/lib/python3.9/site-packages/IPython/extensions', '/home/gerardozinno/.ipython', '/home/gerardozinno/Desktop/Tesi/Code/mlem']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1ee39-e6ea-495f-9151-13c895a6b5fe",
   "metadata": {},
   "source": [
    "# CREATING THE TRAIN AND TEST DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322a4c78-742f-4ecb-b254-43f3e2d85457",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHOLE_DATASET_PATH = Path(\"../data/geotarget/geotarget_30.csv\")\n",
    "TRAIN_PATH = WHOLE_DATASET_PATH.parent / \"train\" / \"train.csv\"\n",
    "TEST_PATH  = WHOLE_DATASET_PATH.parent / \"test\" / \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4eb169f-e23c-40a5-b9e2-6e6067f7239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = .8\n",
    "RAND_SEED   = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d6fd06-d9e2-4c6e-9531-58c84c0d32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (TRAIN_PATH.exists() and TEST_PATH.exists()):\n",
    "    print(f\"Couldn't find the train and/or test dataset(s) in:\\n\\t{TRAIN_PATH}\\n\\t{TEST_PATH}\\n\")\n",
    "    if not WHOLE_DATASET_PATH.exists():\n",
    "        print(f\"ERROR: Couldn't even find {WHOLE_DATASET_PATH}\")\n",
    "        raise Exception(\"Can't find dataset\")\n",
    "    else:\n",
    "        \n",
    "        print(f\"Creating train and test sets with a split of {TRAIN_SPLIT}% - {1-TRAIN_SPLIT:.2f}% and {RAND_SEED} as random seed\")\n",
    "        print('The dataset is split \"as is\", without preprocessing. The selection of the right columns is made by the respective Dataloader')\n",
    "        df = pd.read_csv(WHOLE_DATASET_PATH)\n",
    "        train, test = train_test_split(df, train_size=TRAIN_SPLIT, shuffle=True, random_state=RAND_SEED)\n",
    "        TRAIN_PATH.parent.mkdir(exist_ok=True)\n",
    "        TEST_PATH.parent.mkdir(exist_ok=True)\n",
    "        train.to_csv(TRAIN_PATH, index=False)\n",
    "        test.to_csv(TEST_PATH, index=False)\n",
    "        print(\"train and test datasets created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc3f16-2cf7-4559-86bd-4fbb6cf09b3f",
   "metadata": {},
   "source": [
    "# CREATING THE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f17bfe-547e-440c-b440-e6d3655c156f",
   "metadata": {},
   "source": [
    "# LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105838b0-dd14-4bf8-9b29-b60feb0f1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.geotarget import Geotarget30\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe65b40-32b3-4224-8908-35d18777ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Geotarget30(TRAIN_PATH)\n",
    "test_set  = Geotarget30(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b24ce34-9486-4a1d-8b23-616f7d8c3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=64)\n",
    "test_dataloader  = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86268a1e-f1bb-4437-a3b4-9acf0715cd5a",
   "metadata": {},
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfbb1f8d-1441-4375-912c-6660628ece99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blackboxes.pytorch.utilities import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc4e6d1-9826-46d8-a65a-33c05445e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train in module blackboxes.pytorch.utilities:\n",
      "\n",
      "train(model: torch.nn.modules.module.Module, optimizer: torch.optim.optimizer.Optimizer, loss_fn: object, train_loader: torch.utils.data.dataloader.DataLoader, test_loader: torch.utils.data.dataloader.DataLoader, epochs: int = 20, device: str = 'cpu') -> None\n",
      "    Training loop for training a model.\n",
      "    \n",
      "    Args:\n",
      "        model: model to train.\n",
      "        optimizer: optimizer to use.\n",
      "        loss_fn: loss function.\n",
      "        train_loader: DataLoader for loading the training data.\n",
      "        test_loader: Dataloader for loading the test data\n",
      "        epochs: Training epochs. (Default  = 20)\n",
      "        device: Where to train the model, \"cpu\" or \"cuda\". (Default = \"cpu\")\n",
      "    \n",
      "    Returns:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e7a17-1294-43bd-b016-98ce3b16b0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
