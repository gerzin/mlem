{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees generation on Adult using CFS\n",
    "\n",
    "This notebook Generates the decision trees on Adult with CFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from numba import njit\n",
    "\n",
    "UTILS_RELATIVE_PATH = \"../../../../\"\n",
    "sys.path.append(UTILS_RELATIVE_PATH)\n",
    "\n",
    "MLEM_RELATIVE_PATH = \"../../../../..\"\n",
    "sys.path.append(MLEM_RELATIVE_PATH)\n",
    "\n",
    "LIME_RELATIVE_PATH = \"../../../../../lime/\"\n",
    "sys.path.append(LIME_RELATIVE_PATH)\n",
    "\n",
    "OUTPUT_FOLDER = Path(\"experiment_output\")\n",
    "OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "import logging\n",
    "logging.disable('DEBUG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as distance\n",
    "import multiprocessing\n",
    "import json\n",
    "import numpy as np\n",
    "np.random.seed(4321)\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lime.lime_tabular import LimeTabularExplainer # type: ignore\n",
    "from mlem.utilities import generate_balanced_dataset, save_pickle_bz2, load_pickle_bz2, save_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Adult data\n",
    "\n",
    "loading the Adult RandomForest and the dictionary with all the useful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      8157\n",
      "           1       0.79      0.61      0.69      2690\n",
      "\n",
      "    accuracy                           0.86     10847\n",
      "   macro avg       0.84      0.78      0.80     10847\n",
      "weighted avg       0.86      0.86      0.86     10847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloading.adult import load_adult_data, load_adult_randomforest # type: ignore\n",
    "\n",
    "BB = load_adult_randomforest()\n",
    "BB_DATA = load_adult_data('adult-blackbox-data2.npz')\n",
    "\n",
    "print(classification_report(BB_DATA['y_test'], BB.predict(BB_DATA['X_test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train y_train X_test y_test X_validation y_validation X_validation_noisy y_validation_noisy X_attack_2_per_quantile y_attack_2_per_quantile X_attack_3_per_quantile y_attack_3_per_quantile categorical_features numerical_features categorical_features_mask centroids X_distance_separated y_distance_separated\n"
     ]
    }
   ],
   "source": [
    "print(*BB_DATA.keys(), sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zlist_points(zlist):\n",
    "    \"\"\"\n",
    "    Extract and concatenate all the points from a Z_list\n",
    "    \"\"\"\n",
    "    l = [np.array(zl) for zl in zlist]\n",
    "    return np.concatenate(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the CFS data and creating the DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and splitting #1\n",
      "Loading and splitting #2\n",
      "Loading and splitting #3\n",
      "Loading and splitting #4\n",
      "Loading and splitting #5\n",
      "Loading and splitting #6\n",
      "Loading and splitting #7\n",
      "Loading and splitting #8\n",
      "Loading and splitting #9\n",
      "Loading and splitting #10\n",
      "Loading and splitting #11\n",
      "Loading and splitting #12\n",
      "Loading and splitting #13\n",
      "Loading and splitting #14\n",
      "Loading and splitting #15\n",
      "Loading and splitting #16\n",
      "Loading and splitting #17\n",
      "Loading and splitting #18\n",
      "Loading and splitting #19\n",
      "Loading and splitting #20\n",
      "Loading and splitting #21\n",
      "Loading and splitting #22\n",
      "Loading and splitting #23\n",
      "Loading and splitting #24\n",
      "Loading and splitting #25\n",
      "Loading and splitting #26\n",
      "Loading and splitting #27\n",
      "Loading and splitting #28\n",
      "Loading and splitting #29\n",
      "Loading and splitting #30\n",
      "Loading and splitting #31\n",
      "Loading and splitting #32\n",
      "Loading and splitting #33\n",
      "Loading and splitting #34\n",
      "Loading and splitting #35\n",
      "Loading and splitting #36\n",
      "Loading and splitting #37\n",
      "Loading and splitting #38\n",
      "Loading and splitting #39\n",
      "Loading and splitting #40\n",
      "Loading and splitting #41\n",
      "Loading and splitting #42\n",
      "Loading and splitting #43\n",
      "Loading and splitting #44\n",
      "Loading and splitting #45\n",
      "Loading and splitting #46\n",
      "Loading and splitting #47\n",
      "Loading and splitting #48\n",
      "Loading and splitting #49\n",
      "Loading and splitting #50\n",
      "Loading and splitting #51\n",
      "Loading and splitting #52\n",
      "Loading and splitting #53\n",
      "Loading and splitting #54\n",
      "Loading and splitting #55\n",
      "Loading and splitting #56\n",
      "Loading and splitting #57\n",
      "Loading and splitting #58\n",
      "Loading and splitting #59\n",
      "Loading and splitting #60\n",
      "Loading and splitting #61\n",
      "Loading and splitting #62\n",
      "Loading and splitting #63\n",
      "Loading and splitting #64\n",
      "Loading and splitting #65\n",
      "Loading and splitting #66\n",
      "Loading and splitting #67\n",
      "Loading and splitting #68\n",
      "Loading and splitting #69\n",
      "Loading and splitting #70\n",
      "Loading and splitting #71\n",
      "Loading and splitting #72\n",
      "Loading and splitting #73\n",
      "Loading and splitting #74\n",
      "Loading and splitting #75\n",
      "Loading and splitting #76\n",
      "Loading and splitting #77\n",
      "Loading and splitting #78\n",
      "Loading and splitting #79\n",
      "Loading and splitting #80\n",
      "Loading and splitting #81\n",
      "Loading and splitting #82\n",
      "Loading and splitting #83\n",
      "Loading and splitting #84\n",
      "Loading and splitting #85\n",
      "Loading and splitting #86\n",
      "Loading and splitting #87\n",
      "Loading and splitting #88\n",
      "Loading and splitting #89\n",
      "Loading and splitting #90\n",
      "Loading and splitting #91\n",
      "Loading and splitting #92\n",
      "Loading and splitting #93\n",
      "Loading and splitting #94\n",
      "Loading and splitting #95\n",
      "Loading and splitting #96\n",
      "Loading and splitting #97\n",
      "Loading and splitting #98\n",
      "Loading and splitting #99\n",
      "Loading and splitting #100\n",
      "Loading and splitting #101\n",
      "Loading and splitting #102\n",
      "Loading and splitting #103\n"
     ]
    }
   ],
   "source": [
    "from mlem.utilities import create_decision_tree\n",
    "\n",
    "with open(\"adultRF_CFS.json\", 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        path = OUTPUT_FOLDER / f\"{i}\"\n",
    "        if not path.exists():\n",
    "            path.mkdir(exist_ok=True)\n",
    "            print(f\"Loading and splitting #{i}\")\n",
    "            data = json.loads(line)\n",
    "            # assert (np.array(data['x']) - BB_DATA['X_distance_separated'][i] <= 1e-4).all()\n",
    "            \n",
    "            dt_data_x = extract_zlist_points(data['Z_list'])\n",
    "            dt_data_y = BB.predict(dt_data_x)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(dt_data_x, dt_data_y, test_size=0.33, random_state=42, stratify=dt_data_y)\n",
    "\n",
    "            dt = create_decision_tree(X_train, y_train, use_halving=True)\n",
    "            save_pickle_bz2(path / \"dt.bz2\", dt)\n",
    "            save_txt(path / \"dt_classification_report.txt\", classification_report(y_test, dt.predict(X_test)))\n",
    "            np.savez(path / \"dt-data.npz\", X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19c5d3a3188652f893cd4e64043d7470541fe23a697d87860bb02bfe4b8542de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
