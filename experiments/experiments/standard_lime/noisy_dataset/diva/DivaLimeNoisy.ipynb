{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack on Diva using LIME and noisy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from numba import njit\n",
    "\n",
    "UTILS_RELATIVE_PATH = \"../../../../\"\n",
    "sys.path.append(UTILS_RELATIVE_PATH)\n",
    "\n",
    "MLEM_RELATIVE_PATH = \"../../../../..\"\n",
    "sys.path.append(MLEM_RELATIVE_PATH)\n",
    "\n",
    "LIME_RELATIVE_PATH = \"../../../../../lime/\"\n",
    "sys.path.append(LIME_RELATIVE_PATH)\n",
    "\n",
    "OUTPUT_FOLDER = Path(\"experiment_output\")\n",
    "OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "import logging\n",
    "logging.disable('DEBUG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as distance\n",
    "import multiprocessing\n",
    "\n",
    "np.random.seed(4321)\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lime.lime_tabular import LimeTabularExplainer # type: ignore\n",
    "from mlem.utilities import generate_balanced_dataset, save_pickle_bz2, load_pickle_bz2, save_txt\n",
    "from mlem.ensemble import EnsembleClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the experiment utilities and the mlem module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Adult data\n",
    "\n",
    "loading the Adult RandomForest and the dictionary with all the useful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloading.diva import load_diva_data, load_diva_randomforest # type: ignore\n",
    "\n",
    "BB = load_diva_randomforest()\n",
    "BB_DATA = load_diva_data()\n",
    "\n",
    "print(classification_report(BB_DATA['y_test'], BB.predict(BB_DATA['X_test'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_training_data = BB_DATA['X_train']\n",
    "explainer = LimeTabularExplainer(training_data=explainer_training_data, categorical_features=[i for (i, el) in enumerate(BB_DATA['categorical_features_mask']) if el], random_state=123)\n",
    "\n",
    "def generate_data_lime(x, num_samples):\n",
    "    return explainer.data_inverse(x, num_samples+1, 'gaussian')[1][1:]\n",
    "\n",
    "def generate_local_models_and_neighborhood(x, num_samples):\n",
    "    \"\"\"Generate the lime local models and neighborhood.\n",
    "    \n",
    "    Params:\n",
    "        x - instance aroung which generate the neighborhood and learn the local model\n",
    "        num_samples - number of samples to generate\n",
    "    Return\n",
    "        local_model, x_neigh, y_neigh\n",
    "    \"\"\"\n",
    "    # Exploits Lime to get the neighborhood and the local model\n",
    "    _, models, x_neigh = explainer.explain_instance(\n",
    "        x,\n",
    "        BB.predict_proba,\n",
    "        labels=[0,1],\n",
    "        sampling_method=\"gaussian\",\n",
    "        num_samples=num_samples,\n",
    "        num_features=len(x),\n",
    "    )\n",
    "\n",
    "    # Local model is the one pointed by the instance\n",
    "    local_model = EnsembleClassifier(classifiers=models)\n",
    "    # Generates predictions for the neighborhood\n",
    "    y_neigh = local_model.predict(x_neigh)\n",
    "    return local_model, x_neigh, y_neigh\n",
    "\n",
    "def filter_elements_std(elems, x, std=3):\n",
    "    df_ = pd.DataFrame(elems)\n",
    "    df_['Dist'] = distance.cdist(elems, [x])\n",
    "    mean = df_.Dist.mean()\n",
    "    dev = df_.Dist.std()\n",
    "    closest = df_[df_['Dist'] < mean+std*dev]\n",
    "    return closest.drop(labels=['Dist'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the lime datasets and local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_representatives_x = BB_DATA['X_attack_3_per_quantile']\n",
    "test_representatives_y = BB_DATA['y_attack_3_per_quantile']\n",
    "n_datasets = len(test_representatives_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain each instance and save the local model and the neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the local models and neigh. <span style=\"color:red\"> if they don't already exist </span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save(index, instance):\n",
    "    # wrapper of the above functions to be able to generate the datasets in parallel\n",
    "    output_path = OUTPUT_FOLDER / f\"{index}\"\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "\n",
    "    local_model, x_neigh, y_neigh = generate_local_models_and_neighborhood(instance, 5000)\n",
    "    \n",
    "    local_neighborhood = pd.DataFrame(x_neigh)\n",
    "    local_neighborhood['Target'] = y_neigh\n",
    "\n",
    "    local_neighborhood.to_csv(\"lime_neigh.csv\")\n",
    "    save_pickle_bz2(output_path / \"lime_localmodel.bz2\", local_model)\n",
    "\n",
    "    with open(output_path / \"instance.npy\", \"wb\") as f:\n",
    "        np.save(f, instance)\n",
    "\n",
    "\n",
    "if not any([Path(OUTPUT_FOLDER / f\"{j}\" / \"lime_neigh.csv\").exists() for j in range(len(test_representatives_x))]):\n",
    "    with multiprocessing.Pool(processes=8) as pool:\n",
    "        pool.starmap(generate_and_save, [*enumerate(test_representatives_x)])\n",
    "else:\n",
    "    print(\"The lime neighborhood and local models already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack on the Local Models to create the attack models\n",
    "\n",
    "Attack on the Local Models using the <span style=\"background: green\">noisy dataset</span> labeled by the decision trees to create the shadow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_dataset_x = pd.DataFrame(BB_DATA['X_validation_noisy'])\n",
    "noisy_dataset_y = pd.DataFrame(BB_DATA['y_validation_noisy'])\n",
    "categorical_features_mask = BB_DATA['categorical_features_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the shadow models and the attack models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlem.shadow_models import ShadowModelsManager\n",
    "from mlem.utilities import create_adaboost\n",
    "from mlem.attack_models import AttackModelsManager, AttackStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics_local_model(dataset, true_y, local_model, black_box, output_folder, filename):\n",
    "    local_y = local_model.predict(dataset.to_numpy())\n",
    "    local_bb = black_box.predict(dataset.to_numpy())\n",
    "\n",
    "    report_local = classification_report(true_y.to_numpy(), local_y)\n",
    "    report_bb    = classification_report(true_y.to_numpy(), local_bb)\n",
    "\n",
    "    fidelity = str(pd.DataFrame(local_y == local_bb).value_counts(normalize=True))\n",
    "\n",
    "    with open(output_folder / filename, \"w\") as f:\n",
    "        f.write(\"Statistics on the noisy validation dataset\\n\")\n",
    "        \n",
    "        f.write(\"local model\\n\")\n",
    "        f.write(report_local)\n",
    "\n",
    "        f.write(\"\\nblack box\\n\")\n",
    "        f.write(report_bb)\n",
    "\n",
    "        f.write(\"\\nFidelity between the local model and the black box\\n\")\n",
    "        f.write(fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the attack only if it hasn't already been run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not any([(OUTPUT_FOLDER / f\"{i}\" / \"attack\").exists() for i in range(len(test_representatives_x))]):\n",
    "    \n",
    "    for path in [OUTPUT_FOLDER / f\"{i}\" for i in range(len(test_representatives_x))]:\n",
    "        # load the local model and label the noisy dataset\n",
    "        local_model = load_pickle_bz2(path / \"lime_localmodel.bz2\")\n",
    "\n",
    "        # compute fidelity and performances on the noisy dataset.\n",
    "        # NOTE: The labels associated with the noisy dataset are the same of the clean one.\n",
    "        compute_statistics_local_model(noisy_dataset_x, noisy_dataset_y, local_model, BB, path, \"statistics_noisy_lime.txt\")\n",
    "\n",
    "        x_attack = noisy_dataset_x.to_numpy()    \n",
    "        y_attack = local_model.predict(x_attack)\n",
    "\n",
    "        path_shadow = str(path / \"shadow\")\n",
    "\n",
    "        shadow_models = ShadowModelsManager(\n",
    "            n_models=4,\n",
    "            results_path=path_shadow,\n",
    "            test_size=0.5,\n",
    "            random_state=12,\n",
    "            model_creator_fn=create_adaboost,\n",
    "            categorical_mask=categorical_features_mask\n",
    "        )\n",
    "        # x_attack is the noisy dataset\n",
    "        shadow_models.fit(x_attack, y_attack)\n",
    "\n",
    "        # extracting the dataset for the attack models\n",
    "        attack_models_dataset = shadow_models.get_attack_dataset()\n",
    "\n",
    "        # saving the attack dataset\n",
    "        attack_models_dataset.to_csv(path / \"attack_models_train_dataset.csv\", index=False)\n",
    "\n",
    "        # Creating the attack model for each label using Adaboost\n",
    "        path_attack = str(path / \"attack\")\n",
    "        attack_models = AttackModelsManager(\n",
    "                results_path=path_attack, model_creator_fn=create_adaboost, attack_strategy=AttackStrategy.ONE_PER_LABEL\n",
    "        )\n",
    "        \n",
    "        attack_models.fit(attack_models_dataset)\n",
    "else:\n",
    "    print(\"The attack models already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the test reports of the attack models, it seems that they <span style=\"background: green\">perform better on the class 1</span> with an accuracy of $\\simeq .62$, while the accuracy on the class 0 is $\\simeq .51$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlem.ensemble import HardVotingClassifier, SoftVotingClassifier, KMostSureVotingClassifier\n",
    "from utils.attack_evaluation import evaluate_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_models_0 = [load_pickle_bz2(OUTPUT_FOLDER / f\"{i}\" / \"attack\" / \"0\" / \"model.pkl.bz2\") for i in range(len(test_representatives_x))]\n",
    "attack_models_1 = [load_pickle_bz2(OUTPUT_FOLDER / f\"{i}\" / \"attack\" / \"1\" / \"model.pkl.bz2\") for i in range(len(test_representatives_x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv0 = HardVotingClassifier(classifiers=attack_models_0)\n",
    "hv1 = HardVotingClassifier(classifiers=attack_models_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_attack(hv0, hv1, BB, BB_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv0 = SoftVotingClassifier(classifiers=attack_models_0)\n",
    "sv1 = SoftVotingClassifier(classifiers=attack_models_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_attack(sv0, sv1, BB, BB_DATA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19c5d3a3188652f893cd4e64043d7470541fe23a697d87860bb02bfe4b8542de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
